{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Multibench Example Usage Colab.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Welcome!\n",
        "\n",
        "This example shows a very basic usage case of MultiBench. In particular, it demonstrates how to use MultiBench with the affective computing dataset MOSI, and how to use it with a very simple fusion model. \n",
        "\n",
        "While this will be simple, it will show off most of the capabilities of MultiBench, and most of the conventions at the heart of the system.\n",
        "\n",
        "To begin, let's clone the repo and setup our interpreter to run commands inside the folder."
      ],
      "metadata": {
        "id": "JCnG1gTFJQ-4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vHmaOz8aEZx6",
        "outputId": "1b505191-60c1-4e75-9e8c-2d9ffe089501"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'MultiBench'...\n",
            "remote: Enumerating objects: 4890, done.\u001b[K\n",
            "remote: Counting objects: 100% (1906/1906), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1019/1019), done.\u001b[K\n",
            "remote: Total 4890 (delta 1289), reused 1369 (delta 884), pack-reused 2984\u001b[K\n",
            "Receiving objects: 100% (4890/4890), 46.51 MiB | 17.39 MiB/s, done.\n",
            "Resolving deltas: 100% (3349/3349), done.\n",
            "/content/MultiBench\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/pliang279/MultiBench.git\n",
        "%cd MultiBench"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Try to download the data file for MOSI using the below command. If this does not work for you, please download the data file locally, and upload it to the folder \"/content/MultiBench/data/\""
      ],
      "metadata": {
        "id": "tUqFe87DIYu9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir data\n",
        "!pip install gdown && gdown https://drive.google.com/u/0/uc?id=1szKIqO0t3Be_W91xvf6aYmsVVUa7wDHU"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xwZS6dfGElh8",
        "outputId": "57ada09e-8260-499f-bb01-0d70aec364cc"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘data’: File exists\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.7/dist-packages (4.2.2)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.7/dist-packages (from gdown) (2.23.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from gdown) (4.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from gdown) (4.63.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gdown) (1.15.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from gdown) (3.6.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (1.24.3)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Access denied with the following error:\n",
            "\n",
            " \tCannot retrieve the public link of the file. You may need to change\n",
            "\tthe permission to 'Anyone with the link', or have had many accesses. \n",
            "\n",
            "You may still be able to access the file from the browser:\n",
            "\n",
            "\t https://drive.google.com/u/0/uc?id=1szKIqO0t3Be_W91xvf6aYmsVVUa7wDHU \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As Colab famously has bad handling of Conda env files, we'll install the dependencies manually so that it works. Please note that other systems might require installation of a long list of other dependencies."
      ],
      "metadata": {
        "id": "nd1ZaCe6JOoA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From here, let's import some of MultiBench and get working:"
      ],
      "metadata": {
        "id": "n5S9YcS9J6yk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import sys\n",
        "import os"
      ],
      "metadata": {
        "id": "mk9zuDMrKMAP"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, we'll import and create the dataloader for the MOSI dataset, which we're working with:"
      ],
      "metadata": {
        "id": "U0DyV1CVKpyk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the associated dataloader for affect datasets, which MOSI is a part of.\n",
        "from datasets.affect.get_data import get_dataloader\n",
        "\n",
        "# Create the training, validation, and test-set dataloaders. \n",
        "traindata, validdata, testdata = get_dataloader(\n",
        "    '/content/MultiBench/data/mosi_raw.pkl', robust_test=False, max_pad=True, data_type='mosi', max_seq_len=50)"
      ],
      "metadata": {
        "id": "l5enTYMkKtci"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then, let's define our MultiModal model to test. MultiBench divides models into three separate portions.\n",
        "\n",
        "Firstly, let's define the encoders of the raw modality information, which come from the \"unimodals\" section of MultiBench:"
      ],
      "metadata": {
        "id": "riE35efnK5Jr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Here, we'll import several common modules should you want to mess with this more.\n",
        "from unimodals.common_models import GRU, MLP, Sequential, Identity \n",
        "\n",
        "# As this example is meant to be simple and easy to train, we'll pass in identity\n",
        "# functions for each of the modalities in MOSI:\n",
        "encoders = [Identity().cuda(), Identity().cuda(), Identity().cuda()]"
      ],
      "metadata": {
        "id": "n8ZBils-LGgW"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then, let's define the fusion paradigm, which will govern how we take the current modalities, and combine them.\n",
        "\n",
        "For this example, we'll use the ConcatEarly fusion, which just concatenates the inputs along the second dimension."
      ],
      "metadata": {
        "id": "XBnSFG3TLZFM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import a fusion paradigm, in this case early concatenation.\n",
        "from fusions.common_fusions import ConcatEarly  # noqa\n",
        "\n",
        "# Initialize the fusion module\n",
        "fusion = ConcatEarly().cuda()"
      ],
      "metadata": {
        "id": "ifsONTlIMVyb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lastly, we'll define a 'head' module, which takes the output of the fusion module, and applies transformations to get an output that correponds to our problem - sarcasm detection."
      ],
      "metadata": {
        "id": "-mS5anKyMWPD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "head = Sequential(GRU(409, 512, dropout=True, has_padding=False,\n",
        "                  batch_first=True, last_only=True), MLP(512, 512, 1)).cuda()"
      ],
      "metadata": {
        "id": "6IMQNFDXFJNs"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And with that, we're almost done! Now we just need to put them into one of MultiBench's training loops, and set it running:"
      ],
      "metadata": {
        "id": "2nUXcxm2MndX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Standard supervised learning training loop\n",
        "from training_structures.Supervised_Learning import train, test\n",
        "\n",
        "# For more information regarding parameters for any system, feel free to check out the documentation\n",
        "# at multibench.readthedocs.io!\n",
        "train(encoders, fusion, head, traindata, validdata, 100, task=\"regression\", optimtype=torch.optim.AdamW,\n",
        "      is_packed=False, lr=1e-3, save='mosi_ef_r0.pt', weight_decay=0.01, objective=torch.nn.L1Loss())\n",
        "\n",
        "print(\"Testing:\")\n",
        "model = torch.load('mosi_ef_r0.pt').cuda()\n",
        "test(model, testdata, 'affect', is_packed=False,\n",
        "     criterion=torch.nn.L1Loss(), task=\"posneg-classification\", no_robust=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tG3OYAByJ-sX",
        "outputId": "ac664840-4396-4195-a92f-3d3ffa53feea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 train loss: tensor(1.3309, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 0 valid loss: 1.3881396055221558\n",
            "Saving Best\n",
            "Epoch 1 train loss: tensor(1.3193, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 1 valid loss: 1.385719895362854\n",
            "Saving Best\n",
            "Epoch 2 train loss: tensor(1.3250, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 2 valid loss: 1.3686903715133667\n",
            "Saving Best\n",
            "Epoch 3 train loss: tensor(1.3222, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 3 valid loss: 1.3763189315795898\n",
            "Epoch 4 train loss: tensor(1.3209, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 4 valid loss: 1.3935108184814453\n",
            "Epoch 5 train loss: tensor(1.3185, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 5 valid loss: 1.3834254741668701\n",
            "Epoch 6 train loss: tensor(1.3160, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 6 valid loss: 1.391663670539856\n",
            "Epoch 7 train loss: tensor(1.3205, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 7 valid loss: 1.3926382064819336\n",
            "Epoch 8 train loss: tensor(1.3181, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 8 valid loss: 1.3880600929260254\n",
            "Epoch 9 train loss: tensor(1.3162, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 9 valid loss: 1.3847376108169556\n",
            "Epoch 10 train loss: tensor(1.3189, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 10 valid loss: 1.3774747848510742\n",
            "Epoch 11 train loss: tensor(1.3192, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 11 valid loss: 1.3812885284423828\n",
            "Epoch 12 train loss: tensor(1.3154, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 12 valid loss: 1.390760898590088\n",
            "Epoch 13 train loss: tensor(1.3189, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 13 valid loss: 1.3933579921722412\n",
            "Epoch 14 train loss: tensor(1.3148, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 14 valid loss: 1.3749574422836304\n",
            "Epoch 15 train loss: tensor(1.3162, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 15 valid loss: 1.387494444847107\n",
            "Epoch 16 train loss: tensor(1.3127, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 16 valid loss: 1.6177618503570557\n",
            "Epoch 17 train loss: tensor(1.3275, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 17 valid loss: 1.4156113862991333\n",
            "Epoch 18 train loss: tensor(1.3109, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 18 valid loss: 1.458567500114441\n",
            "Epoch 19 train loss: tensor(1.2642, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 19 valid loss: 1.364851951599121\n",
            "Saving Best\n",
            "Epoch 20 train loss: tensor(1.2212, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 20 valid loss: 1.3744850158691406\n",
            "Epoch 21 train loss: tensor(1.0659, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 21 valid loss: 1.378214955329895\n",
            "Epoch 22 train loss: tensor(0.9987, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 22 valid loss: 1.2856768369674683\n",
            "Saving Best\n",
            "Epoch 23 train loss: tensor(0.9500, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 23 valid loss: 1.1618746519088745\n",
            "Saving Best\n",
            "Epoch 24 train loss: tensor(0.9120, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 24 valid loss: 1.1730754375457764\n",
            "Epoch 25 train loss: tensor(0.8536, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 25 valid loss: 1.1779531240463257\n",
            "Epoch 26 train loss: tensor(0.8490, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 26 valid loss: 1.1971670389175415\n",
            "Epoch 27 train loss: tensor(0.8182, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 27 valid loss: 1.1774905920028687\n",
            "Epoch 28 train loss: tensor(0.7840, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 28 valid loss: 1.1172412633895874\n",
            "Saving Best\n",
            "Epoch 29 train loss: tensor(0.7394, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 29 valid loss: 1.0931432247161865\n",
            "Saving Best\n",
            "Epoch 30 train loss: tensor(0.6999, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 30 valid loss: 1.1739411354064941\n",
            "Epoch 31 train loss: tensor(0.6899, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 31 valid loss: 1.1358418464660645\n",
            "Epoch 32 train loss: tensor(0.6668, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 32 valid loss: 1.0865757465362549\n",
            "Saving Best\n",
            "Epoch 33 train loss: tensor(0.6574, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 33 valid loss: 1.0610039234161377\n",
            "Saving Best\n",
            "Epoch 34 train loss: tensor(0.6263, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 34 valid loss: 1.0557646751403809\n",
            "Saving Best\n",
            "Epoch 35 train loss: tensor(0.6081, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 35 valid loss: 1.0812879800796509\n",
            "Epoch 36 train loss: tensor(0.5850, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 36 valid loss: 1.058321475982666\n",
            "Epoch 37 train loss: tensor(0.5565, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 37 valid loss: 1.0548226833343506\n",
            "Saving Best\n",
            "Epoch 38 train loss: tensor(0.5572, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 38 valid loss: 1.107828140258789\n",
            "Epoch 39 train loss: tensor(0.5383, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 39 valid loss: 1.0692119598388672\n",
            "Epoch 40 train loss: tensor(0.5182, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 40 valid loss: 1.05642569065094\n",
            "Epoch 41 train loss: tensor(0.4944, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 41 valid loss: 1.047702670097351\n",
            "Saving Best\n",
            "Epoch 42 train loss: tensor(0.5176, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 42 valid loss: 1.1552175283432007\n",
            "Epoch 43 train loss: tensor(0.4912, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 43 valid loss: 1.1234911680221558\n",
            "Epoch 44 train loss: tensor(0.4662, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 44 valid loss: 1.0850801467895508\n",
            "Epoch 45 train loss: tensor(0.4622, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 45 valid loss: 1.0889346599578857\n",
            "Epoch 46 train loss: tensor(0.4619, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 46 valid loss: 1.0555202960968018\n",
            "Epoch 47 train loss: tensor(0.4385, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 47 valid loss: 1.1086392402648926\n",
            "Epoch 48 train loss: tensor(0.4398, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 48 valid loss: 1.1042399406433105\n",
            "Epoch 49 train loss: tensor(0.4213, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 49 valid loss: 1.1200507879257202\n",
            "Epoch 50 train loss: tensor(0.4050, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 50 valid loss: 1.1294007301330566\n",
            "Epoch 51 train loss: tensor(0.4142, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 51 valid loss: 1.138630986213684\n",
            "Epoch 52 train loss: tensor(0.3864, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 52 valid loss: 1.1288071870803833\n",
            "Epoch 53 train loss: tensor(0.3930, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 53 valid loss: 1.0880576372146606\n",
            "Epoch 54 train loss: tensor(0.3533, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 54 valid loss: 1.1002473831176758\n",
            "Epoch 55 train loss: tensor(0.3667, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 55 valid loss: 1.132964849472046\n",
            "Epoch 56 train loss: tensor(0.3675, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 56 valid loss: 1.155429720878601\n",
            "Epoch 57 train loss: tensor(0.3528, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 57 valid loss: 1.1537388563156128\n",
            "Epoch 58 train loss: tensor(0.3576, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 58 valid loss: 1.108046293258667\n",
            "Epoch 59 train loss: tensor(0.3577, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 59 valid loss: 1.0822762250900269\n",
            "Epoch 60 train loss: tensor(0.3415, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 60 valid loss: 1.0710722208023071\n",
            "Epoch 61 train loss: tensor(0.3167, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 61 valid loss: 1.1091512441635132\n",
            "Epoch 62 train loss: tensor(0.3276, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 62 valid loss: 1.107180118560791\n",
            "Epoch 63 train loss: tensor(0.3208, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 63 valid loss: 1.1037997007369995\n",
            "Epoch 64 train loss: tensor(0.3041, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 64 valid loss: 1.0833042860031128\n",
            "Epoch 65 train loss: tensor(0.3252, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 65 valid loss: 1.0648620128631592\n",
            "Epoch 66 train loss: tensor(0.3015, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 66 valid loss: 1.1332956552505493\n",
            "Epoch 67 train loss: tensor(0.2835, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 67 valid loss: 1.160487174987793\n",
            "Epoch 68 train loss: tensor(0.3014, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 68 valid loss: 1.1095640659332275\n",
            "Epoch 69 train loss: tensor(0.2927, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 69 valid loss: 1.1174366474151611\n",
            "Epoch 70 train loss: tensor(0.2852, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 70 valid loss: 1.0823800563812256\n",
            "Epoch 71 train loss: tensor(0.3080, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 71 valid loss: 1.104067087173462\n",
            "Epoch 72 train loss: tensor(0.2771, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 72 valid loss: 1.1053662300109863\n",
            "Epoch 73 train loss: tensor(0.2572, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 73 valid loss: 1.129191517829895\n",
            "Epoch 74 train loss: tensor(0.2799, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 74 valid loss: 1.110538363456726\n",
            "Epoch 75 train loss: tensor(0.2813, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 75 valid loss: 1.1203924417495728\n",
            "Epoch 76 train loss: tensor(0.2433, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 76 valid loss: 1.169894814491272\n",
            "Epoch 77 train loss: tensor(0.2730, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 77 valid loss: 1.1525421142578125\n",
            "Epoch 78 train loss: tensor(0.2738, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 78 valid loss: 1.125364065170288\n",
            "Epoch 79 train loss: tensor(0.2440, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 79 valid loss: 1.150625467300415\n",
            "Epoch 80 train loss: tensor(0.2434, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 80 valid loss: 1.1324822902679443\n",
            "Epoch 81 train loss: tensor(0.2462, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Epoch 81 valid loss: 1.110476016998291\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "And with that, you've taken your first step into using MultiBench! We hope you find the library useful, and feel free to make an issue on GitHub should there be any confusions regarding how to use an aspect of the package."
      ],
      "metadata": {
        "id": "wPVLMGGtM99W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "mgx9AHpZNP_c"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}