{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Multibench Example Usage On Colab Part 2: MFAS.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Welcome!\n",
        "\n",
        "This example shows a slightly more complicated training paradigm in MultiBench. Namely, we'll run a MFAS, or MultiModal Fusion Architecture Search, system on the AVMNIST system.\n",
        "\n",
        "This tutorial assumes you've followed along with the first tutorial, as we'll focus on the differences between this task and standard supervised learning in MultiBench.\n",
        "\n",
        "To begin, let's clone the repo and setup our interpreter to run commands inside the folder."
      ],
      "metadata": {
        "id": "JCnG1gTFJQ-4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vHmaOz8aEZx6",
        "outputId": "9c2582b3-efb5-402e-a3ea-47eee8d8a28d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'MultiBench' already exists and is not an empty directory.\n",
            "/content/MultiBench\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/pliang279/MultiBench.git\n",
        "%cd MultiBench"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Try to download the data file for MOSI using the below command. If this does not work for you, please download the data file locally, and upload it to the folder \"/content/MultiBench/\""
      ],
      "metadata": {
        "id": "tUqFe87DIYu9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir data\n",
        "!mkdir temp\n",
        "!pip install gdown && gdown https://drive.google.com/u/0/uc?id=1KvKynJJca5tDtI5Mmp6CoRh9pQywH8Xp&export=download"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xwZS6dfGElh8",
        "outputId": "95dcc949-3675-48e6-ac48-162512d9bcc9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘data’: File exists\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.7/dist-packages (4.2.2)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from gdown) (4.6.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gdown) (1.15.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from gdown) (4.63.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from gdown) (3.6.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.7/dist-packages (from gdown) (2.23.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (2.10)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Access denied with the following error:\n",
            "\n",
            " \tCannot retrieve the public link of the file. You may need to change\n",
            "\tthe permission to 'Anyone with the link', or have had many accesses. \n",
            "\n",
            "You may still be able to access the file from the browser:\n",
            "\n",
            "\t https://drive.google.com/u/0/uc?id=1KvKynJJca5tDtI5Mmp6CoRh9pQywH8Xp \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tar -xvzf avmnist.tar.gz "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mGu8IwWKNksl",
        "outputId": "94fa1b81-cb3c-40ec-e580-d6da260dfefa"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "avmnist/\n",
            "avmnist/test_labels.npy\n",
            "avmnist/image/\n",
            "avmnist/image/train_data.npy\n",
            "avmnist/image/test_data.npy\n",
            "avmnist/audio/\n",
            "avmnist/audio/train_data.npy\n",
            "avmnist/audio/test_data.npy\n",
            "avmnist/train_labels.npy\n",
            "avmnist/avmnist_temp/\n",
            "avmnist/avmnist_temp/train_labels.npy\n",
            "avmnist/avmnist_temp/image/\n",
            "avmnist/avmnist_temp/image/test_data.npy\n",
            "avmnist/avmnist_temp/image/train_data.npy\n",
            "avmnist/avmnist_temp/test_labels.npy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As Colab famously has bad handling of Conda env files, we'll install the dependencies manually so that it works. Please note that other systems might require installation of a long list of other dependencies."
      ],
      "metadata": {
        "id": "nd1ZaCe6JOoA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install memory-profiler"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fSn8hNwXOAIh",
        "outputId": "0fbe9ea2-0c6f-4bdc-8486-36539acdf706"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: memory-profiler in /usr/local/lib/python3.7/dist-packages (0.60.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from memory-profiler) (5.4.8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From here, let's import some of MultiBench and get working. First, we'll import what is required from all MultiBench programs:"
      ],
      "metadata": {
        "id": "n5S9YcS9J6yk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import os\n",
        "import torch\n",
        "from torch import nn"
      ],
      "metadata": {
        "id": "mk9zuDMrKMAP"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then, we'll import the AVMNIST dataloaders, and create the training, validation, and test dataloaders respectively:"
      ],
      "metadata": {
        "id": "ECC6sy3AOSRe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import utils.surrogate as surr # This imports a learned cost model from configurations to accuracies.\n",
        "from datasets.avmnist.get_data import get_dataloader # This imports the AVMNIST dataloader\n",
        "\n",
        "\n",
        "\n",
        "traindata, validdata, testdata = get_dataloader(\n",
        "    '/content/MultiBench/avmnist', batch_size=32)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8AFa28b6ORRp",
        "outputId": "37cca817-1cc7-4b57-b953-0b658f9564c6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To train the MFAS model, you don't need to feed in a fusion layer nor a classification head, as both of those are looked after through MFAS. Instead, you just need to provide the pretrained encoder files for each modality encoder, and the associated hyperparameters:"
      ],
      "metadata": {
        "id": "jmEnJPUzPOtK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from training_structures.architecture_search import train # This imports the MFAS training method.\n",
        "\n",
        "s_data = train(['pretrained/avmnist/image_encoder.pt', \n",
        "                'pretrained/avmnist/audio_encoder.pt'], \n",
        "               16, # Size of encoder output\n",
        "               10, # Number of classes\n",
        "               [(6, 12, 24), (6, 12, 24, 48, 96)], # Output of each layer within the unimodal encoders\n",
        "               traindata, # Training data loader.\n",
        "               validdata, # Validation data loader\n",
        "               surr.SimpleRecurrentSurrogate().cuda(), # Surrogate instance\n",
        "               (3, 5, 2), # Search space of the fusion layer\n",
        "               epochs=6 # Number of epochs\n",
        "               )\n"
      ],
      "metadata": {
        "id": "x8MBODIWQgfN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7a1a266-73ed-4fcd-8f6b-2a6fb7deac08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Search iteration 0 \n",
            "Progressive step 0 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Acc: 0.2884\n",
            "dev Acc: 0.3344\n",
            "train Acc: 0.3467\n",
            "dev Acc: 0.3826\n",
            "train Acc: 0.3621\n",
            "dev Acc: 0.3854\n",
            "train Acc: 0.3738\n",
            "dev Acc: 0.4144\n",
            "train Acc: 0.3995\n",
            "dev Acc: 0.4416\n",
            "train Acc: 0.4165\n",
            "dev Acc: 0.4476\n",
            "train Acc: 0.1811\n",
            "dev Acc: 0.2056\n",
            "train Acc: 0.2689\n",
            "dev Acc: 0.3054\n",
            "train Acc: 0.3103\n",
            "dev Acc: 0.3222\n",
            "train Acc: 0.3262\n",
            "dev Acc: 0.3454\n",
            "train Acc: 0.3383\n",
            "dev Acc: 0.3638\n",
            "train Acc: 0.3448\n",
            "dev Acc: 0.3634\n"
          ]
        }
      ]
    }
  ]
}